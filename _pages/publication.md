---
permalink: /publication/
author_profile: true
---
(Selected Publications. * equal contribution, # corresponding author)

## Preprint

- **R-Stitch: Dynamic Trajectory Stitching for Efficient Reasoning**  
Zhuokun Chen, Zeren Chen, Jiahao He, Mingkui Tan, Jianfei Cai, Bohan Zhuang#  
\[[Paper](https://arxiv.org/abs/2507.17307)\]

- **FPSAttention: Training-Aware FP8 and Sparsity Co-Design for Fast Video Diffusion**  
Akide Liu\*, Zeyu Zhang\*, Zhexin Li, Xuehai Bai, Yizeng Han, Jiasheng Tang, Yuanjie Xing, Jichao Wu, Mingyang Yang, Weihua Chen, Jiahao He, Yuanyu He, Fan Wang#, Gholamreza Haffari, Bohan Zhuang#  
\[[Paper](https://arxiv.org/abs/2506.04648)\]\[[Project](https://fps.ziplab.co)\]  

- **ZPressor: Bottleneck-Aware Compression for Scalable Feed-Forward 3DGS**  
Weijie Wang#, Donny Y. Chen#, Zeyu Zhang, Duochao Shi, Akide Liu, Bohan Zhuang  
\[[Paper](https://arxiv.org/abs/2505.23734)\]\[[Project](https://lhmd.top/zpressor/)\]

- **Video-BLADE: Block-Sparse Attention Meets Step Distillation for Efficient Video Generation**  
Youping Gu\*, Xiaolong Li\*, Yuhao Hu, Bohan Zhuang  
\[[Paper](https://arxiv.org/abs/2508.10774)\]\[[Project](https://ziplab.co/BLADE-Homepage/)\]

- **Motion Anything: Any to Motion Generation**  
Zeyu Zhang, Yiran Wang, Wei Mao, Danning Li, Rui Zhao, Biao Wu, Zirui Song, Bohan Zhuang, Ian Reid, Richard Hartley  
\[[Paper](https://arxiv.org/abs/2503.06955)\]\[[Project](https://steve-zeyu-zhang.github.io/MotionAnything/)\]  



## 2025

- **Neighboring Autoregressive Modeling for Efficient Visual Generation**  
Yefei He\*, Yuanyu He\*, Shaoxuan He\*, Feng Chen\*, Hong Zhou, Kaipeng Zhang, Bohan Zhuang#   
\[[Paper](https://arxiv.org/pdf/2503.10696)\]\[[Code](https://github.com/ThisisBillhe/NAR)\]\[[Project](https://yuanyu0.github.io/nar/)\]  **ICCV 2025**


- **ZipVL: Efficient Large Vision-Language Models with Dynamic Token Sparsification**  
Yefei He, Feng Chen, Jing Liu, Wenqi Shao, Hong Zhou, Kaipeng Zhang, Bohan Zhuang  
\[[Paper](https://arxiv.org/abs/2410.08584)\]  **ICCV 2025**


- **Frequency-Aware Autoregressive Modeling for Efficient High-Resolution Image Synthesis**  
Zhuokun Chen, Jugang Fan, Zhuowei Yu, Bohan Zhuang#, Mingkui Tan#  
\[[Paper]()\]\[[Code]()\]  **ICCV 2025**


- **ZipAR: Parallel Autoregressive Image Generation through Spatial Locality**  
Yefei He, Feng Chen, Yuanyu He, Shaoxuan He, Hong Zhou, Kaipeng Zhang, Bohan Zhuang  
\[[Paper](https://arxiv.org/pdf/2412.04062)\]\[[Code](https://github.com/ThisisBillhe/ZipAR)\]  **ICML 2025**


- **T-Stitch: Accelerating Sampling in Pre-Trained Diffusion Models with Trajectory Stitching**  
Zizheng Pan, Bohan Zhuang#, De-An Huang, Weili Nie, Zhiding Yu, Chaowei Xiao, Jianfei Cai, Anima Anandkumar  
\[[Paper](https://arxiv.org/abs/2402.14167)\]\[[Code](https://github.com/NVlabs/T-Stitch)\]\[[Project](https://t-stitch.github.io/)\] **ICLR 2025**


- **Are Large Vision Language Models Good Game Players?**  
Xinyu Wang, Bohan Zhuang, Qi Wu  
\[[Paper](https://arxiv.org/pdf/2503.02358)\]\[[Code](https://github.com/xinke-wang/LVLM-Playground)\] **ICLR 2025**


- **Channel Merging: Preserving Specialization for Merged Experts**  
Mingyang Zhang, Jing Liu, Ganggui Ding, Xinyi Yu, Linlin Ou, Bohan Zhuang#  
\[[Paper](https://arxiv.org/abs/2412.15283)\] **AAAI 2025** **(**<font color="red"><b>Oral</b></font>**)**  


## 2024

- **MiniCache: KV Cache Compression in Depth Dimension for Large Language Models**  
Akide Liu, Jing Liu, Zizheng Pan, Yefei He, Gholamreza Haffari, Bohan Zhuang#  
\[[Paper](https://openreview.net/forum?id=sgVOjDqUMT)\]\[[Code](https://minicache.vmv.re)\]   **NeurIPS 2024**


- **ZipCache: Accurate and Efficient KV Cache Quantization with Salient Token Identification**  
Yefei He, Luoming Zhang, Weijia Wu, Jing Liu, Hong Zhou, Bohan Zhuang#  
\[[Paper](https://openreview.net/forum?id=5t4ZAkPiJs)\]\[[Code](https://github.com/ThisisBillhe/ZipCache/)\]  **NeurIPS 2024**


- **MVSplat360: Feed Forward 360Â° Scene Synthesis from Sparse Views**  
Yuedong Chen, Chuanxia Zheng, Haofei Xu, Bohan Zhuang, Andrea Vedaldi, Tat-Jen Cham, Jianfei Cai   
\[[Paper](https://openreview.net/forum?id=B0OWOkMwhz)\]\[[Homepage](donydchen.github.io/mvsplat360)\]  **NeurIPS 2024**


- **QLLM: Accurate and Efficient Low-Bitwidth Quantization for Large Language Models**  
Jing Liu, Ruihao Gong, Xiuying Wei, Zhiwei Dong, Jianfei Cai, Bohan Zhuang#  
\[[Paper](https://openreview.net/forum?id=FIplmUWdm3)\]\[[Code](https://github.com/ziplab/QLLM)\]   **ICLR 2024**


- **Object-Aware Inversion and Reassembly for Image Editing**    
Zhen Yang, Ganggui Ding, Wen Wang, Hao Chen#, Bohan Zhuang#, Chunhua Shen    
\[[Paper](https://openreview.net/forum?id=dpcVXiMlcv)\]\[[Homepage](https://aim-uofa.github.io/OIR-Diffusion/)\] **ICLR 2024**


- **EfficientDM: Efficient Quantization-Aware Fine-Tuning of Low-Bit Diffusion Models**  
Hefei He, Jing Liu, Weijia Wu, Hong Zhou, Bohan Zhuang#   
\[[Paper](https://openreview.net/forum?id=UmMa3UNDAz)\]\[[Code](https://github.com/ThisisBillhe/EfficientDM)\] **ICLR 2024** **(**<font color="red"><b>Spotlight</b></font>**)**  


- **GMAI-MMBench: A Comprehensive Multimodal Evaluation Benchmark Towards General Medical AI**  
Pengcheng Chen*, Jin Ye*#, Guoan Wang*, Yanjun Li, Zhongying Deng, Wei Li, Tianbin Li, Haodong Duan, Ziyan Huang, Yanzhou Su, Benyou Wang, Shaoting Zhang, Bin Fu, Jianfei Cai, Bohan Zhuang, Eric J Seibel, Junjun He, Yu Qiao  
\[[Paper](https://www.arxiv.org/abs/2408.03361)\]\[[Homepage](https://uni-medical.github.io/GMAI-MMBench.github.io/)\] **NeurIPS 2024 Datasets and Benchmarks Track**

- **LongVLM: Efficient Long Video Understanding via Large Language Models**  
Yuetian Weng, Mingfei Han, Haoyu He, Xiaojun Chang, Bohan Zhuang#  
\[[Paper](https://arxiv.org/abs/2404.03384)\]\[[Code](https://github.com/ziplab/LongVLM)\] **ECCV 2024** **(**<font color="red"><b>Oral</b></font>**)**  

- **MVSplat: Efficient 3D Gaussian Splatting from Sparse Multi-View Images**  
Yuedong Chen, Haofei Xu, Chuanxia Zheng, Bohan Zhuang, Marc Pollefeys, Andreas Geiger, Tat-Jen Cham, Jianfei Cai  
\[[Paper](https://arxiv.org/abs/2403.14627)\]\[[Homepage](https://donydchen.github.io/mvsplat/)\] **ECCV 2024** **(**<font color="red"><b>Oral</b></font>**)**  

- **Stitched ViTs are Flexible Vision Backbones**  
Zizheng Pan, Jing Liu, Haoyu He, Jianfei Cai, Bohan Zhuang#  
\[[Paper](https://arxiv.org/abs/2307.00154)\]\[[Code](https://github.com/ziplab/SN-Netv2)\] **ECCV 2024**

- **Motion Mamba: Efficient and Long Sequence Motion Generation**  
Zeyu Zhang, Akide Liu, Ian Reid, Richard Hartley, Bohan Zhuang, Hao Tang  
\[[Paper](https://arxiv.org/abs/2403.07487)\]\[[HomePage](https://steve-zeyu-zhang.github.io/MotionMamba/)\] **ECCV 2024**

- **Efficient Stitchable Task Adaptation**  
Haoyu He, Zizheng Pan, Jing Liu, Jianfei Cai, Bohan Zhuang#  
\[[Paper](https://openaccess.thecvf.com/content/CVPR2024/papers/He_Efficient_Stitchable_Task_Adaptation_CVPR_2024_paper.pdf)\] **CVPR 2024**

- **ModaVerse: Efficiently Transforming Modalities with LLMs**  
Xinyu Wang, Bohan Zhuang, Qi Wu  
\[[Paper](https://openaccess.thecvf.com/content/CVPR2024/papers/Wang_ModaVerse_Efficiently_Transforming_Modalities_with_LLMs_CVPR_2024_paper.pdf)\]\[[Code](https://github.com/xinke-wang/ModaVerse)\] **CVPR 2024**

- **LoRAPrune: Structured Pruning Meets Low-Rank Parameter-Efficient Fine-Tuning**  
Mingyang Zhang, Hao Chen, Chunhua Shen, Zhen Yang, Linlin Ou, Xinyi Yu, Bohan Zhuang  
\[[Paper](https://aclanthology.org/2024.findings-acl.178/)\]\[[Code](https://github.com/aim-uofa/LoRAPrune)\] **ACL Findings 2024**

- **SAM-Med3D-MoE: Towards a Non-Forgetting Segment Anything Model via Mixture of Experts for 3D Medical Image Segmentation**  
Guoan Wang*, Jin Ye*, Junlong Cheng, Tianbin Li, Zhaolin Chen, Jianfei Cai, Junjun He, Bohan Zhuang#  
\[[Paper](https://arxiv.org/abs/2407.04938)\] **MICCAI 2024**

- **ME-Switch: A Memory-Efficient Expert Switching Framework for Large Language Models**  
Jing Liu, Ruihao Gong, Mingyang Zhang, Yefei He, Jianfei Cai, Bohan Zhuang#  
\[[Paper](https://arxiv.org/pdf/2402.14758)\]

- **Enhancing Perception Capabilities of Multimodal LLMs with Training-Free Fusion**  
Zhuokun Chen, Jinwu Hu, Zeshuai Deng, Yufeng Wang, Bohan Zhuang#, Mingkui Tan#  
\[[Paper](https://arxiv.org/pdf/2403.18716)\]

- **Evaluating and Advancing Multimodal Large Language Models in Ability Lens**  
Feng Chen, Chenhui Gou, Jing Liu, Yang Yang, Zhaoyang Li, Jiyuan Zhang, Zhenbang Sun, Bohan Zhuang, Qi Wu  
\[[Paper](https://arxiv.org/pdf/2403.18613)\]



## 2023
- **Stitchable Neural Networks**  
Zizheng Pan; Jianfei Cai; Bohan Zhuang#  
\[[Paper](https://arxiv.org/abs/2302.06586)\]\[[Homepage](https://snnet.github.io/)\] **CVPR 2023** **(**<font color="red"><b>Highlight</b></font>**)**  

- **PTQD: Accurate Post-Training Quantization for Diffusion Models**  
Yefei He, Luping Liu, Jing Liu, Weijia Wu, Hong Zhou#, Bohan Zhuang#  
\[[Paper](https://openreview.net/forum?id=Y3g1PV5R9l)\]\[[Code](https://github.com/ziplab/PTQD)\] **NeurIPS 2023**

- **Mask Propagation for Efficient Video Semantic Segmentation**  
Yuetian Weng, Mingfei Han, Haoyu He, Mingjie Li, Xiaojun Chang, Bohan Zhuang#  
\[[Paper](https://openreview.net/forum?id=6ljXBlojde)\]\[[Code](https://github.com/ziplab/MPVSS)\] **NeurIPS 2023**

- **Second-Order Degradation and Reconstruction for Test-Time Image Super-Resolution**  
Zeshuai Deng, Zhuokun Chen, Shuaicheng Niu, Thomas H. Li, Bohan Zhuang#, Mingkui Tan#  
\[[Paper](https://openreview.net/forum?id=IZRlMABK4l)\]\[[Code](https://github.com/DengZeshuai/SRTTA)\] **NeurIPS 2023**

- **Sensitivity-Aware Visual Parameter-Efficient Fine-Tuning**  
Haoyu He, Jianfei Cai, Jing Zhang, Dacheng Tao, Bohan Zhuang#  
\[[Paper](https://openaccess.thecvf.com/content/ICCV2023/papers/He_Sensitivity-Aware_Visual_Parameter-Efficient_Fine-Tuning_ICCV_2023_paper.pdf)\]\[[Code](https://github.com/ziplab/SPT)\]  **ICCV 2023** **(**<font color="red"><b>Oral</b></font>**)**  

- **BiViT: Extremely Compressed Binary Vision Transformer**  
Yefei He, Zhenyu Lou, Luoming Zhang, Hong Zhou#, Bohan Zhuang#  
\[[Paper](https://openaccess.thecvf.com/content/ICCV2023/papers/He_BiViT_Extremely_Compressed_Binary_Vision_Transformers_ICCV_2023_paper.pdf)\] **ICCV 2023**

- **Dynamic Focus-aware Positional Queries for Semantic Segmentation**  
Haoyu He, Jianfei Cai, Zizheng Pan, Jing Liu, Jing Zhang, Dacheng Tao, Bohan Zhuang#  
\[[Paper](https://openaccess.thecvf.com/content/CVPR2023/papers/He_Dynamic_Focus-Aware_Positional_Queries_for_Semantic_Segmentation_CVPR_2023_paper.pdf)\]\[[Code](https://github.com/ziplab/FASeg)\]  **CVPR 2023**

- **End-to-end One-shot Human Parsing**  
Haoyu He, Jing Zhang, Bohan Zhuang#, Jianfei Cai, Dacheng Tao  
\[[Paper](https://arxiv.org/abs/2105.01241)\]\[[Code](https://github.com/Charleshhy/One-shot-Human-Parsing)\]  **TPAMI 2023**

- **Single-path Bit Sharing for Automatic Loss-aware Model Compression**  
Jing Liu, Bohan Zhuang, Peng Chen, Yong Guo, Chunhua Shen, Jianfei Cai, Mingkui Tan  
\[[Paper](https://arxiv.org/abs/2101.04935)\] **TPAMI 2023**

- **Pruning Self-attentions into Convolutional Layers in Single Path**  
Haoyu He, Jing Liu, Zizheng Pan, Jianfei Cai, Jing Zhang, Dacheng Tao, Bohan Zhuang#  
\[[Paper](https://arxiv.org/abs/2111.11802)\]\[[Code](https://github.com/ziplab/SPViT)\]   **TPAMI 2023**

- **A Survey on Efficient Training of Transformers**  
Bohan Zhuang#, Jing Liu, Zizheng Pan, Haoyu He, Yuetian Weng, Chunhua Shen  
\[[Paper](https://arxiv.org/abs/2302.01107)\] **IJCAI 2023**



## 2022
- **EcoFormer: Energy-Saving Attention with Linear Complexity**  
Jing Liu, Zizheng Pan, Haoyu He, Jianfei Cai, Bohan Zhuang#  
\[[Paper](https://openreview.net/forum?id=MK_130d4Y0)\]\[[Code](https://github.com/ziplab/EcoFormer)\] **NeurIPS 2022** **(**<font color="red"><b>Spotlight</b></font>**)**  

- **Fast Vision Transformers with HiLo Attention**  
Zizheng Pan, Jianfei Cai, Bohan Zhuang#  
\[[Paper](https://openreview.net/forum?id=Pyd6Rh9r1OT)\]\[[Code](https://github.com/ziplab/LITv2)\] **NeurIPS 2022** **(**<font color="red"><b>Spotlight</b></font>**)**  

- **Automated Progressive Learning for Efficient Training of Vision Transformers**  
Changlin Li, Bohan Zhuang#, Guangrun Wang, Xiaodan Liang, Xiaojun Chang, Yi Yang  
\[[Paper](https://openaccess.thecvf.com/content/CVPR2022/papers/Li_Automated_Progressive_Learning_for_Efficient_Training_of_Vision_Transformers_CVPR_2022_paper.pdf)\] **CVPR 2022**

- **Less is More: Pay Less Attention in Vision Transformers**  
Zizheng Pan, Bohan Zhuang#, Haoyu He, Jing Liu, Jianfei Cai  
\[[Paper](https://ojs.aaai.org/index.php/AAAI/article/view/20099)\]\[[Code](https://github.com/ziplab/LIT)\] **AAAI 2022**

- **An Efficient Spatio-Temporal Pyramid Transformer for Action Detection**  
Yuetian Weng, Zizheng Pan, Mingfei Han, Xiaojun Chang, Bohan Zhuang#  
\[[Paper](https://link.springer.com/content/pdf/10.1007/978-3-031-19830-4_21.pdf)\] **ECCV 2022**

- **Structured Binary Neural Networks for Image Recognition**  
Bohan Zhuang, Chunhua Shen, Mingkui Tan, Peng Chen, Lingqiao Liu, Ian Reid  
\[[Paper](https://link.springer.com/article/10.1007/s11263-022-01638-0)\] **IJCV 2022**


## 2021

- **Mesa: A Memory-saving Training Framework for Transformers**  
Zizheng Pan, Peng Chen, Haoyu He, Jing Liu, Jianfei Cai, Bohan Zhuang#  
\[[Paper](https://arxiv.org/pdf/2111.11124)\]\[[Code](https://github.com/ziplab/Mesa)\]


- **Sharpness-aware Quantization for Deep Neural Networks**  
Jing Liu, Jianfei Cai, Bohan Zhuang#  
\[[Paper](https://arxiv.org/pdf/2111.12273)\]\[[Code](https://github.com/ziplab/SAQ)\]


- **Scalable Visual Transformers with Hierarchical Pooling**  
Zizheng Pan, Bohan Zhuang#, Jing Liu, Haoyu He, Jianfei Cai  
\[[Paper](https://openaccess.thecvf.com/content/ICCV2021/papers/Pan_Scalable_Vision_Transformers_With_Hierarchical_Pooling_ICCV_2021_paper.pdf)\]\[[Code](https://github.com/ziplab/HVT)\] **ICCV 2021**


- **FATNN: Fast and Accurate Ternary Neural Networks**  
Peng Chen, Bohan Zhuang*, Chunhua Shen  
\[[Paper](https://openaccess.thecvf.com/content/ICCV2021/papers/Chen_FATNN_Fast_and_Accurate_Ternary_Neural_Networks_ICCV_2021_paper.pdf)\]\[[Code](https://github.com/ziplab/QTool)\] **ICCV 2021**


- **Effective Training of Convolutional Neural Networks with Low-bitwidth Weights and Activations**  
Bohan Zhuang, Mingkui Tan, Jing Liu, Lingqiao Liu, Ian Reid, Chunhua Shen  
\[[Paper](https://arxiv.org/pdf/1908.04680.pdf)\]\[[Code](https://github.com/bohanzhuang/Towards-Effective-Low-bitwidth-Convolutional-Neural-Networks)\] **TPAMI 2021**


- **Discrimination-aware Network Pruning for Deep Model Compression**  
Jing Liu*, Bohan Zhuang*, Zhuangwei Zhuang*, Yong Guo, Junzhou Huang, Jinhui Zhu, Mingkui Tan  
\[[Paper](https://ieeexplore.ieee.org/document/9384353)\]\[[Code](https://github.com/SCUT-AILab/DCP)\] **TPAMI 2021**


- **AQD: Towards Accurate Quantized Object Detection**  
Peng Chen*, Jing Liu*, Bohan Zhuang#, Mingkui Tan, Chunhua Shen  
\[[Paper](https://arxiv.org/abs/2104.07913)\]\[[Code](https://github.com/ziplab/QTool)\] **CVPR 2021** **(**<font color="red"><b>Oral</b></font>**)**  


