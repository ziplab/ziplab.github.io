---
permalink: /publication/
author_profile: true
---
(Selected Publications. * equal contribution, # corresponding author)

## Preprint
- **Neighboring Autoregressive Modeling for Efficient Visual Generation**  
Yefei He\*, Yuanyu He\*, Shaoxuan He\*, Feng Chen\*, Hong Zhou, Kaipeng Zhang, Bohan Zhuang# 
\[[Paper](https://arxiv.org/pdf/2503.10696)\]\[[Code](https://github.com/ThisisBillhe/NAR)\]\[[Project](https://yuanyu0.github.io/nar/)\]

- **ZipAR: Accelerating Autoregressive Image Generation through Spatial Locality**
Yefei He, Feng Chen, Yuanyu He, Shaoxuan He, Hong Zhou, Kaipeng Zhang, Bohan Zhuang#
\[[Paper](https://arxiv.org/pdf/2412.04062)\]\[[Code](https://github.com/ThisisBillhe/ZipAR)\]

- **ZipVL: Efficient Large Vision-Language Models with Dynamic Token Sparsification**  
Yefei He, Feng Chen, Jing Liu, Wenqi Shao, Hong Zhou, Kaipeng Zhang, Bohan Zhuang  
\[[Paper](https://arxiv.org/pdf/2403.15377)\]

- **ME-Switch: A Memory-Efficient Expert Switching Framework for Large Language Models**  
Jing Liu, Ruihao Gong, Mingyang Zhang, Yefei He, Jianfei Cai, Bohan Zhuang#  
\[[Paper](https://arxiv.org/pdf/2402.14758)\]

- **Enhancing Perception Capabilities of Multimodal LLMs with Training-Free Fusion**  
Zhuokun Chen, Jinwu Hu, Zeshuai Deng, Yufeng Wang, Bohan Zhuang#, Mingkui Tan#  
\[[Paper](https://arxiv.org/pdf/2403.18716)\]

- **Evaluating and Advancing Multimodal Large Language Models in Ability Lens**  
Feng Chen, Chenhui Gou, Jing Liu, Yang Yang, Zhaoyang Li, Jiyuan Zhang, Zhenbang Sun, Bohan Zhuang, Qi Wu  
\[[Paper](https://arxiv.org/pdf/2403.18613)\]




## 2025

- **T-Stitch: Accelerating Sampling in Pre-Trained Diffusion Models with Trajectory Stitching**  
Zizheng Pan, Bohan Zhuang#, De-An Huang, Weili Nie, Zhiding Yu, Chaowei Xiao, Jianfei Cai, Anima Anandkumar  
\[[Paper](https://arxiv.org/abs/2402.14167)\]\[[Code](https://github.com/NVlabs/T-Stitch)\]\[[Project](https://t-stitch.github.io/)\] **ICLR 2025**


- **Are Large Vision Language Models Good Game Players?**  
Xinyu Wang, Bohan Zhuang, Qi Wu  
\[[Paper](https://arxiv.org/pdf/2503.02358)\]\[[Code](https://github.com/xinke-wang/LVLM-Playground)\] **ICLR 2025**


- **Channel Merging: Preserving Specialization for Merged Experts**  
Mingyang Zhang, Jing Liu, Ganggui Ding, Xinyi Yu, Linlin Ou, Bohan Zhuang#  
\[[Paper](https://arxiv.org/abs/2412.15283)\] **AAAI 2025** **(**<font color="red"><b>Oral</b></font>**)**  


## 2024

- **MiniCache: KV Cache Compression in Depth Dimension for Large Language Models**
Akide Liu, Jing Liu, Zizheng Pan, Yefei He, Gholamreza Haffari, Bohan Zhuang#
\[[Paper](https://openreview.net/forum?id=sgVOjDqUMT)\]   **NeurIPS 2024**


- **ZipCache: Accurate and Efficient KV Cache Quantization with Salient Token Identification**
Yefei He, Luoming Zhang, Weijia Wu, Jing Liu, Hong Zhou, Bohan Zhuang#
\[[Paper](https://openreview.net/forum?id=5t4ZAkPiJs)\]   **NeurIPS 2024**


- **MVSplat360: Feed Forward 360Â° Scene Synthesis from Sparse Views**
Yuedong Chen, Chuanxia Zheng, Haofei Xu, Bohan Zhuang, Andrea Vedaldi, Tat-Jen Cham, Jianfei Cai 
\[[Paper](https://openreview.net/forum?id=B0OWOkMwhz)\]   **NeurIPS 2024**


- **QLLM: Accurate and Efficient Low-Bitwidth Quantization for Large Language Models**
Jing Liu, Ruihao Gong, Xiuying Wei, Zhiwei Dong, Jianfei Cai, Bohan Zhuang#
\[[Paper](https://openreview.net/forum?id=FIplmUWdm3)\]   **ICLR 2024**


- **Object-Aware Inversion and Reassembly for Image Editing**  
Zhen Yang, Ganggui Ding, Wen Wang, Hao Chen#, Bohan Zhuang#, Chunhua Shen  
\[[Paper](https://openreview.net/forum?id=dpcVXiMlcv)\] **ICLR 2024**


- **EfficientDM: Efficient Quantization-Aware Fine-Tuning of Low-Bit Diffusion Models**
Hefei He, Jing Liu, Weijia Wu, Hong Zhou, Bohan Zhuang# 
\[[Paper](https://openreview.net/forum?id=UmMa3UNDAz)\]  **ICLR 2024** **(**<font color="red"><b>Spotlight</b></font>**)**  


- **GMAI-MMBench: A Comprehensive Multimodal Evaluation Benchmark Towards General Medical AI**  
Pengcheng Chen*, Jin Ye*#, Guoan Wang*, Yanjun Li, Zhongying Deng, Wei Li, Tianbin Li, Haodong Duan, Ziyan Huang, Yanzhou Su, Benyou Wang, Shaoting Zhang, Bin Fu, Jianfei Cai, Bohan Zhuang, Eric J Seibel, Junjun He, Yu Qiao  
\[[Paper](https://www.arxiv.org/abs/2408.03361)\] **NeurIPS 2024 Datasets and Benchmarks Track**

- **LongVLM: Efficient Long Video Understanding via Large Language Models**  
Yuetian Weng, Mingfei Han, Haoyu He, Xiaojun Chang, Bohan Zhuang#  
\[[Paper](https://arxiv.org/abs/2404.03384)\] **ECCV 2024** **(**<font color="red"><b>Oral</b></font>**)**  

- **MVSplat: Efficient 3D Gaussian Splatting from Sparse Multi-View Images**  
Yuedong Chen, Haofei Xu, Chuanxia Zheng, Bohan Zhuang, Marc Pollefeys, Andreas Geiger, Tat-Jen Cham, Jianfei Cai  
\[[Paper](https://arxiv.org/abs/2403.14627)\] **ECCV 2024** **(**<font color="red"><b>Oral</b></font>**)**  

- **Stitched ViTs are Flexible Vision Backbones**  
Zizheng Pan, Jing Liu, Haoyu He, Jianfei Cai, Bohan Zhuang#  
\[[Paper](https://arxiv.org/abs/2307.00154)\] **ECCV 2024**

- **Motion Mamba: Efficient and Long Sequence Motion Generation**  
Zeyu Zhang, Akide Liu, Ian Reid, Richard Hartley, Bohan Zhuang, Hao Tang  
\[[Paper](https://arxiv.org/abs/2403.07487)\] **ECCV 2024**

- **Efficient Stitchable Task Adaptation**  
Haoyu He, Zizheng Pan, Jing Liu, Jianfei Cai, Bohan Zhuang#  
\[[Paper](https://openaccess.thecvf.com/content/CVPR2024/papers/He_Efficient_Stitchable_Task_Adaptation_CVPR_2024_paper.pdf)\] **CVPR 2024**

- **ModaVerse: Efficiently Transforming Modalities with LLMs**  
Xinyu Wang, Bohan Zhuang, Qi Wu  
\[[Paper](https://openaccess.thecvf.com/content/CVPR2024/papers/Wang_ModaVerse_Efficiently_Transforming_Modalities_with_LLMs_CVPR_2024_paper.pdf)\] **CVPR 2024**

- **LoRAPrune: Structured Pruning Meets Low-Rank Parameter-Efficient Fine-Tuning**  
Mingyang Zhang, Hao Chen, Chunhua Shen, Zhen Yang, Linlin Ou, Xinyi Yu, Bohan Zhuang  
\[[Paper](https://aclanthology.org/2024.findings-acl.178/)\] **ACL Findings 2024**

- **SAM-Med3D-MoE: Towards a Non-Forgetting Segment Anything Model via Mixture of Experts for 3D Medical Image Segmentation**  
Guoan Wang*, Jin Ye*, Junlong Cheng, Tianbin Li, Zhaolin Chen, Jianfei Cai, Junjun He, Bohan Zhuang#  
\[[Paper](https://arxiv.org/abs/2407.04938)\] **MICCAI 2024**


## 2023
- **Stitchable Neural Networks**  
Zizheng Pan; Jianfei Cai; Bohan Zhuang#  
\[[Paper](https://arxiv.org/abs/2302.06586)\] **CVPR 2023** **(**<font color="red"><b>Highlight</b></font>**)**  

- **PTQD: Accurate Post-Training Quantization for Diffusion Models**  
Yefei He, Luping Liu, Jing Liu, Weijia Wu, Hong Zhou#, Bohan Zhuang#  
\[[Paper](https://openreview.net/forum?id=Y3g1PV5R9l)\] **NeurIPS 2023**

- **Mask Propagation for Efficient Video Semantic Segmentation**  
Yuetian Weng, Mingfei Han, Haoyu He, Mingjie Li, Xiaojun Chang, Bohan Zhuang#  
\[[Paper](https://openreview.net/forum?id=6ljXBlojde)\] **NeurIPS 2023**

- **Second-Order Degradation and Reconstruction for Test-Time Image Super-Resolution**  
Zeshuai Deng, Zhuokun Chen, Shuaicheng Niu, Thomas H. Li, Bohan Zhuang#, Mingkui Tan#  
\[[Paper](https://openreview.net/forum?id=IZRlMABK4l)\] **NeurIPS 2023**

 **Sensitivity-Aware Visual Parameter-Efficient Fine-Tuning**  
Haoyu He, Jianfei Cai, Jing Zhang, Dacheng Tao, Bohan Zhuang#  
\[[Paper](https://openaccess.thecvf.com/content/ICCV2023/papers/He_Sensitivity-Aware_Visual_Parameter-Efficient_Fine-Tuning_ICCV_2023_paper.pdf)\] **ICCV 2023** **(**<font color="red"><b>Oral</b></font>**)**  

- **BiViT: Extremely Compressed Binary Vision Transformer**  
Yefei He, Zhenyu Lou, Luoming Zhang, Hong Zhou#, Bohan Zhuang#  
\[[Paper](https://openaccess.thecvf.com/content/ICCV2023/papers/He_BiViT_Extremely_Compressed_Binary_Vision_Transformers_ICCV_2023_paper.pdf)\] **ICCV 2023**

- **Dynamic Focus-aware Positional Queries for Semantic Segmentation**  
Haoyu He, Jianfei Cai, Zizheng Pan, Jing Liu, Jing Zhang, Dacheng Tao, Bohan Zhuang#  
\[[Paper](https://openaccess.thecvf.com/content/CVPR2023/papers/He_Dynamic_Focus-Aware_Positional_Queries_for_Semantic_Segmentation_CVPR_2023_paper.pdf)\] **CVPR 2023**

- **End-to-end One-shot Human Parsing**  
Haoyu He, Jing Zhang, Bohan Zhuang#, Jianfei Cai, Dacheng Tao  
\[[Paper](https://arxiv.org/abs/2105.01241)\]**TPAMI 2023**

- **Single-path Bit Sharing for Automatic Loss-aware Model Compression**  
Jing Liu, Bohan Zhuang, Peng Chen, Yong Guo, Chunhua Shen, Jianfei Cai, Mingkui Tan  
\[[Paper](https://arxiv.org/abs/2101.04935)\]**TPAMI 2023**

- **Pruning Self-attentions into Convolutional Layers in Single Path**  
Haoyu He, Jing Liu, Zizheng Pan, Jianfei Cai, Jing Zhang, Dacheng Tao, Bohan Zhuang#  
\[[Paper](https://arxiv.org/abs/2111.11802)\]**TPAMI 2023**

- **A Survey on Efficient Training of Transformers**  
Bohan Zhuang#, Jing Liu, Zizheng Pan, Haoyu He, Yuetian Weng, Chunhua Shen  
\[[Paper](https://arxiv.org/abs/2302.01107)\] **IJCAI 2023**


## 2022
- **EcoFormer: Energy-Saving Attention with Linear Complexity**  
Jing Liu, Zizheng Pan, Haoyu He, Jianfei Cai, Bohan Zhuang#  
\[[Paper](https://openreview.net/forum?id=MK_130d4Y0)\] **NeurIPS 2022** **(**<font color="red"><b>Spotlight</b></font>**)**  

- **Fast Vision Transformers with HiLo Attention**  
Zizheng Pan, Jianfei Cai, Bohan Zhuang#  
\[[Paper](https://openreview.net/forum?id=Pyd6Rh9r1OT)\] **NeurIPS 2022** **(**<font color="red"><b>Spotlight</b></font>**)**  

- **Automated Progressive Learning for Efficient Training of Vision Transformers**  
Changlin Li, Bohan Zhuang#, Guangrun Wang, Xiaodan Liang, Xiaojun Chang, Yi Yang  
\[[Paper](https://openaccess.thecvf.com/content/CVPR2022/papers/Li_Automated_Progressive_Learning_for_Efficient_Training_of_Vision_Transformers_CVPR_2022_paper.pdf)\] **CVPR 2022**

- **Less is More: Pay Less Attention in Vision Transformers**  
Zizheng Pan, Bohan Zhuang#, Haoyu He, Jing Liu, Jianfei Cai  
\[[Paper](https://ojs.aaai.org/index.php/AAAI/article/view/20099)\] **AAAI 2022**

- **An Efficient Spatio-Temporal Pyramid Transformer for Action Detection**  
Yuetian Weng, Zizheng Pan, Mingfei Han, Xiaojun Chang, Bohan Zhuang#  
\[[Paper](https://link.springer.com/content/pdf/10.1007/978-3-031-19830-4_21.pdf)\] **ECCV 2022**

- **Structured Binary Neural Networks for Image Recognition**  
Bohan Zhuang, Chunhua Shen, Mingkui Tan, Peng Chen, Lingqiao Liu, Ian Reid  
\[[Paper](https://link.springer.com/article/10.1007/s11263-022-01638-0)\]**IJCV 2022**


## 2021

- **Mesa: A Memory-saving Training Framework for Transformers**
Zizheng Pan, Peng Chen, Haoyu He, Jing Liu, Jianfei Cai, Bohan Zhuang#
\[[Paper](https://arxiv.org/pdf/2111.11124)\]\[[Code](https://github.com/ziplab/Mesa)\]


- **Sharpness-aware Quantization for Deep Neural Networks**
Jing Liu, Jianfei Cai, Bohan Zhuang#
\[[Paper](https://arxiv.org/pdf/2111.12273)\]


- **Scalable Visual Transformers with Hierarchical Pooling**  
Zizheng Pan, Bohan Zhuang#, Jing Liu, Haoyu He, Jianfei Cai  
\[[Paper](https://openaccess.thecvf.com/content/ICCV2021/papers/Pan_Scalable_Vision_Transformers_With_Hierarchical_Pooling_ICCV_2021_paper.pdf\] **ICCV 2021**


- **FATNN: Fast and Accurate Ternary Neural Networks**  
Peng Chen, Bohan Zhuang*, Chunhua Shen  
\[[Paper](https://openaccess.thecvf.com/content/ICCV2021/papers/Chen_FATNN_Fast_and_Accurate_Ternary_Neural_Networks_ICCV_2021_paper.pdf)\] **ICCV 2021**


- **Effective Training of Convolutional Neural Networks with Low-bitwidth Weights and Activations**  
Bohan Zhuang, Mingkui Tan, Jing Liu, Lingqiao Liu, Ian Reid, Chunhua Shen  
\[[Paper](https://arxiv.org/pdf/1908.04680.pdf)\] **TPAMI 2021**

- **Discrimination-aware Network Pruning for Deep Model Compression**  
Jing Liu*, Bohan Zhuang*, Zhuangwei Zhuang*, Yong Guo, Junzhou Huang, Jinhui Zhu, Mingkui Tan  
\[[Paper](https://ieeexplore.ieee.org/document/9384353)\] **TPAMI 2021**

- **AQD: Towards Accurate Quantized Object Detection**  
Peng Chen*, Jing Liu*, Bohan Zhuang#, Mingkui Tan, Chunhua Shen  
\[[Paper](https://arxiv.org/abs/2104.07913)\] **CVPR 2021** **(**<font color="red"><b>Oral</b></font>**)**  


