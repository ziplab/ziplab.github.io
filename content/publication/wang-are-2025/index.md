---
title: Are Large Vision Language Models Good Game Players?
authors:
- Xinyu Wang
- Bohan Zhuang
- Qi Wu
date: '2025-03-01'
publishDate: '2025-03-14T12:48:48.088932Z'
publication_types:
- manuscript
publication: '*arXiv*'
doi: 10.48550/arXiv.2503.02358
abstract: "Large Vision Language Models (LVLMs) have demonstrated remarkable abilities\
  \ in understanding and reasoning about both visual and textual information. However,\
  \ existing evaluation methods for LVLMs, primarily based on benchmarks like Visual\
  \ Question Answering and image captioning, often fail to capture the full scope\
  \ of LVLMs' capabilities. These benchmarks are limited by issues such as inadequate\
  \ assessment of detailed visual perception, data contamination, and a lack of focus\
  \ on multi-turn reasoning. To address these challenges, we propose method, a game-based\
  \ evaluation framework designed to provide a comprehensive assessment of LVLMs'\
  \ cognitive and reasoning skills in structured environments. method uses a set of\
  \ games to evaluate LVLMs on four core tasks: Perceiving, Question Answering, Rule\
  \ Following, and End-to-End Playing, with each target task designed to assess specific\
  \ abilities, including visual perception, reasoning, decision-making, etc. Based\
  \ on this framework, we conduct extensive experiments that explore the limitations\
  \ of current LVLMs, such as handling long structured outputs and perceiving detailed\
  \ and dense elements. Code and data are publicly available at https://github.com/xinke-wang/LVLM-Playground."
links:
- name: URL
  url: http://arxiv.org/abs/2503.02358
---
